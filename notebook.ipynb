{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/opyate/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply\n",
    "from keras.layers import RepeatVector, Dense, Activation, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model, Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "\n",
    "# our stuff\n",
    "from synth import *\n",
    "from utils import *\n",
    "from const import Tx, Ty, n_a, n_s, input_vocab, output_vocab, output_vocab_inv\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/device:CPU:0\n",
      "/device:GPU:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check GPU\n",
    "from tensorflow.python.client import device_lib\n",
    "[print(x.name) for x in device_lib.list_local_devices()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"five minutes and twenty nine seconds to eleven o'clock at night\",\n",
       " '22:54:31',\n",
       " datetime.time(22, 54, 31))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Returns input,output,dt\n",
    "# Run once to see an example.\n",
    "load_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: twenty three minutes and twenty one seconds past four o'clock in the morning\n",
      "Target: 04:23:21\n",
      "Input shape: (1, 128, 102)\n",
      "Target shape: (1, 8, 11)\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# One-hot representations of load_time()'s input and output\n",
    "# will be fed into the model.\n",
    "\n",
    "i, o, _ = load_time()\n",
    "\n",
    "print('Input:', i)\n",
    "print('Target:', o)\n",
    "\n",
    "ioh, ooh = one_hot([i], [o], Tx, Ty, input_vocab, output_vocab)\n",
    "\n",
    "print('Input shape:', ioh.shape)\n",
    "print('Target shape:', ooh.shape)\n",
    "print(*ooh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ioh, \"input one-hot\", has shape (128,102), i.e. it can accept an input string of up to (or padded to) 128 characters of a possible vocabulary of 102 characters.\n",
    "- ooh, \"output one-hot\", has shape (8,11), i.e. the model will predict 8 characters of the form 'hh:mm:ss' of a possible vocabulary of all digits and colon ':'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defined shared layers as global variables\n",
    "repeator = RepeatVector(Tx)\n",
    "concatenator = Concatenate(axis=-1)\n",
    "densor = Dense(1, activation = \"relu\")\n",
    "# softmax(axis = 1) from utils.py\n",
    "activator = Activation(softmax, name='attention_weights')\n",
    "dotor = Dot(axes = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_step_attention(a, s_prev):\n",
    "    \"\"\"\n",
    "    Performs one step of attention: Outputs a context vector computed as a dot product of the attention weights\n",
    "    \"alphas\" and the hidden states \"a\" of the Bi-LSTM.\n",
    "    \n",
    "    Arguments:\n",
    "    a -- hidden state output of the Bi-LSTM, numpy-array of shape (m, Tx, 2*n_a)\n",
    "    s_prev -- previous hidden state of the (post-attention) LSTM, numpy-array of shape (m, n_s)\n",
    "    \n",
    "    Returns:\n",
    "    context -- context vector, input of the next (post-attetion) LSTM cell\n",
    "    \"\"\"\n",
    "    \n",
    "    # Use repeator to repeat s_prev to be of shape (m, Tx, n_s) so that you can concatenate it with all hidden states \"a\"\n",
    "    s_prev = repeator(s_prev)\n",
    "    # Use concatenator to concatenate a and s_prev on the last axis\n",
    "    concat = concatenator([a, s_prev])\n",
    "    # Use densor to propagate concat through a small fully-connected neural network to compute the \"energies\" variable e.\n",
    "    e = densor(concat)\n",
    "    # Use activator and e to compute the attention weights \"alphas\"\n",
    "    alphas = activator(e)\n",
    "    # Use dotor together with \"alphas\" and \"a\" to compute the context vector to be given to the next (post-attention) LSTM-cell\n",
    "    context = dotor([alphas, a])\n",
    "    \n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "post_activation_LSTM_cell = LSTM(n_s, return_state = True)\n",
    "output_layer = Dense(len(output_vocab), activation=softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model(Tx, Ty, n_a, n_s, human_vocab_size, machine_vocab_size):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    Tx -- length of the input sequence\n",
    "    Ty -- length of the output sequence\n",
    "    n_a -- hidden state size of the Bi-LSTM\n",
    "    n_s -- hidden state size of the post-attention LSTM\n",
    "    human_vocab_size -- size of the python dictionary \"human_vocab\"\n",
    "    machine_vocab_size -- size of the python dictionary \"machine_vocab\"\n",
    "\n",
    "    Returns:\n",
    "    model -- Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    # input of shape (Tx,)\n",
    "    X = Input(shape=(Tx, human_vocab_size))\n",
    "    \n",
    "    # s0 and c0, initial hidden state for the decoder LSTM of shape (n_s,)\n",
    "    s0 = Input(shape=(n_s,), name='s0')\n",
    "    c0 = Input(shape=(n_s,), name='c0')\n",
    "    \n",
    "    s = s0\n",
    "    c = c0\n",
    "    \n",
    "    outputs = []\n",
    "    \n",
    "    # pre-attention Bi-LSTM\n",
    "    a = Bidirectional(LSTM(n_a, return_sequences=True))(X)\n",
    "    \n",
    "    for t in range(Ty):\n",
    "    \n",
    "        # perform one step of the attention mechanism to get back the context vector at step t\n",
    "        context = one_step_attention(a, s)\n",
    "        \n",
    "        # apply the post-attention LSTM cell to the \"context\" vector.\n",
    "        s, _, c = post_activation_LSTM_cell(context, initial_state=[s, c])\n",
    "        \n",
    "        # apply Dense layer to the hidden state output of the post-attention LSTM\n",
    "        out = output_layer(s)\n",
    "        \n",
    "        outputs.append(out)\n",
    "    \n",
    "    # create model instance taking three inputs and returning the list of outputs.\n",
    "    model = Model(inputs=[X, s0, c0], outputs=outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = get_model(Tx, Ty, n_a, n_s, len(input_vocab), len(output_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 128, 102)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "s0 (InputLayer)                 (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 128, 128)     85504       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)  (None, 128, 128)     0           s0[0][0]                         \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 lstm_1[1][0]                     \n",
      "                                                                 lstm_1[2][0]                     \n",
      "                                                                 lstm_1[3][0]                     \n",
      "                                                                 lstm_1[4][0]                     \n",
      "                                                                 lstm_1[5][0]                     \n",
      "                                                                 lstm_1[6][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 128, 256)     0           bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[0][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[1][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[2][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[3][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[4][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[5][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[6][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[7][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128, 1)       257         concatenate_1[0][0]              \n",
      "                                                                 concatenate_1[1][0]              \n",
      "                                                                 concatenate_1[2][0]              \n",
      "                                                                 concatenate_1[3][0]              \n",
      "                                                                 concatenate_1[4][0]              \n",
      "                                                                 concatenate_1[5][0]              \n",
      "                                                                 concatenate_1[6][0]              \n",
      "                                                                 concatenate_1[7][0]              \n",
      "__________________________________________________________________________________________________\n",
      "attention_weights (Activation)  (None, 128, 1)       0           dense_1[0][0]                    \n",
      "                                                                 dense_1[1][0]                    \n",
      "                                                                 dense_1[2][0]                    \n",
      "                                                                 dense_1[3][0]                    \n",
      "                                                                 dense_1[4][0]                    \n",
      "                                                                 dense_1[5][0]                    \n",
      "                                                                 dense_1[6][0]                    \n",
      "                                                                 dense_1[7][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 1, 128)       0           attention_weights[0][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[1][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[2][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[3][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[4][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[5][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[6][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[7][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "c0 (InputLayer)                 (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 128), (None, 131584      dot_1[0][0]                      \n",
      "                                                                 s0[0][0]                         \n",
      "                                                                 c0[0][0]                         \n",
      "                                                                 dot_1[1][0]                      \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "                                                                 dot_1[2][0]                      \n",
      "                                                                 lstm_1[1][0]                     \n",
      "                                                                 lstm_1[1][2]                     \n",
      "                                                                 dot_1[3][0]                      \n",
      "                                                                 lstm_1[2][0]                     \n",
      "                                                                 lstm_1[2][2]                     \n",
      "                                                                 dot_1[4][0]                      \n",
      "                                                                 lstm_1[3][0]                     \n",
      "                                                                 lstm_1[3][2]                     \n",
      "                                                                 dot_1[5][0]                      \n",
      "                                                                 lstm_1[4][0]                     \n",
      "                                                                 lstm_1[4][2]                     \n",
      "                                                                 dot_1[6][0]                      \n",
      "                                                                 lstm_1[5][0]                     \n",
      "                                                                 lstm_1[5][2]                     \n",
      "                                                                 dot_1[7][0]                      \n",
      "                                                                 lstm_1[6][0]                     \n",
      "                                                                 lstm_1[6][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 11)           1419        lstm_1[0][0]                     \n",
      "                                                                 lstm_1[1][0]                     \n",
      "                                                                 lstm_1[2][0]                     \n",
      "                                                                 lstm_1[3][0]                     \n",
      "                                                                 lstm_1[4][0]                     \n",
      "                                                                 lstm_1[5][0]                     \n",
      "                                                                 lstm_1[6][0]                     \n",
      "                                                                 lstm_1[7][0]                     \n",
      "==================================================================================================\n",
      "Total params: 218,764\n",
      "Trainable params: 218,764\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.005, beta_1=0.9, beta_2=0.999, decay=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1000/1000 [==============================] - 249s 249ms/step - loss: 7.4680 - dense_2_loss_1: 0.5685 - dense_2_loss_2: 1.8177 - dense_2_loss_3: 0.0662 - dense_2_loss_4: 0.7530 - dense_2_loss_5: 1.3919 - dense_2_loss_6: 0.0893 - dense_2_loss_7: 1.1506 - dense_2_loss_8: 1.6309 - dense_2_acc_1: 0.7456 - dense_2_acc_2: 0.2887 - dense_2_acc_3: 0.9990 - dense_2_acc_4: 0.6544 - dense_2_acc_5: 0.4214 - dense_2_acc_6: 0.9990 - dense_2_acc_7: 0.5162 - dense_2_acc_8: 0.3718 - val_loss: 3.9772 - val_dense_2_loss_1: 0.1837 - val_dense_2_loss_2: 1.2240 - val_dense_2_loss_3: 0.0010 - val_dense_2_loss_4: 0.3723 - val_dense_2_loss_5: 0.7840 - val_dense_2_loss_6: 0.0025 - val_dense_2_loss_7: 0.5519 - val_dense_2_loss_8: 0.8578 - val_dense_2_acc_1: 0.9379 - val_dense_2_acc_2: 0.5170 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 0.8308 - val_dense_2_acc_5: 0.6563 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 0.7843 - val_dense_2_acc_8: 0.6907\n",
      "Epoch 2/1000\n",
      "1000/1000 [==============================] - 246s 246ms/step - loss: 2.6574 - dense_2_loss_1: 0.0892 - dense_2_loss_2: 0.8709 - dense_2_loss_3: 9.2967e-04 - dense_2_loss_4: 0.1441 - dense_2_loss_5: 0.6607 - dense_2_loss_6: 0.0016 - dense_2_loss_7: 0.3695 - dense_2_loss_8: 0.5203 - dense_2_acc_1: 0.9781 - dense_2_acc_2: 0.6787 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 0.9587 - dense_2_acc_5: 0.6989 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 0.8702 - dense_2_acc_8: 0.8431 - val_loss: 1.7518 - val_dense_2_loss_1: 0.0416 - val_dense_2_loss_2: 0.5917 - val_dense_2_loss_3: 7.7978e-04 - val_dense_2_loss_4: 0.0417 - val_dense_2_loss_5: 0.5488 - val_dense_2_loss_6: 0.0014 - val_dense_2_loss_7: 0.2369 - val_dense_2_loss_8: 0.2889 - val_dense_2_acc_1: 0.9950 - val_dense_2_acc_2: 0.8277 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 0.9948 - val_dense_2_acc_5: 0.7700 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 0.9258 - val_dense_2_acc_8: 0.9375\n",
      "Epoch 3/1000\n",
      "1000/1000 [==============================] - 246s 246ms/step - loss: 1.2043 - dense_2_loss_1: 0.0280 - dense_2_loss_2: 0.3841 - dense_2_loss_3: 5.8911e-04 - dense_2_loss_4: 0.0355 - dense_2_loss_5: 0.3811 - dense_2_loss_6: 0.0011 - dense_2_loss_7: 0.1754 - dense_2_loss_8: 0.1985 - dense_2_acc_1: 0.9985 - dense_2_acc_2: 0.9165 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 0.9957 - dense_2_acc_5: 0.8874 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 0.9504 - dense_2_acc_8: 0.9647 - val_loss: 0.7640 - val_dense_2_loss_1: 0.0184 - val_dense_2_loss_2: 0.2369 - val_dense_2_loss_3: 4.9146e-04 - val_dense_2_loss_4: 0.0292 - val_dense_2_loss_5: 0.2177 - val_dense_2_loss_6: 8.7674e-04 - val_dense_2_loss_7: 0.1276 - val_dense_2_loss_8: 0.1327 - val_dense_2_acc_1: 0.9988 - val_dense_2_acc_2: 0.9639 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 0.9967 - val_dense_2_acc_5: 0.9678 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 0.9661 - val_dense_2_acc_8: 0.9812\n",
      "Epoch 4/1000\n",
      "1000/1000 [==============================] - 246s 246ms/step - loss: 0.5421 - dense_2_loss_1: 0.0138 - dense_2_loss_2: 0.1632 - dense_2_loss_3: 4.2113e-04 - dense_2_loss_4: 0.0245 - dense_2_loss_5: 0.1459 - dense_2_loss_6: 7.0531e-04 - dense_2_loss_7: 0.0968 - dense_2_loss_8: 0.0967 - dense_2_acc_1: 0.9990 - dense_2_acc_2: 0.9791 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 0.9974 - dense_2_acc_5: 0.9811 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 0.9779 - dense_2_acc_8: 0.9860 - val_loss: 0.3775 - val_dense_2_loss_1: 0.0098 - val_dense_2_loss_2: 0.1088 - val_dense_2_loss_3: 3.6506e-04 - val_dense_2_loss_4: 0.0203 - val_dense_2_loss_5: 0.1000 - val_dense_2_loss_6: 6.2443e-04 - val_dense_2_loss_7: 0.0701 - val_dense_2_loss_8: 0.0675 - val_dense_2_acc_1: 0.9994 - val_dense_2_acc_2: 0.9907 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 0.9978 - val_dense_2_acc_5: 0.9874 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 0.9875 - val_dense_2_acc_8: 0.9915\n",
      "Epoch 5/1000\n",
      "1000/1000 [==============================] - 246s 246ms/step - loss: 0.2904 - dense_2_loss_1: 0.0078 - dense_2_loss_2: 0.0796 - dense_2_loss_3: 2.8825e-04 - dense_2_loss_4: 0.0162 - dense_2_loss_5: 0.0799 - dense_2_loss_6: 4.6403e-04 - dense_2_loss_7: 0.0538 - dense_2_loss_8: 0.0522 - dense_2_acc_1: 0.9993 - dense_2_acc_2: 0.9937 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 0.9982 - dense_2_acc_5: 0.9885 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 0.9912 - dense_2_acc_8: 0.9937 - val_loss: 0.2230 - val_dense_2_loss_1: 0.0064 - val_dense_2_loss_2: 0.0583 - val_dense_2_loss_3: 2.3609e-04 - val_dense_2_loss_4: 0.0140 - val_dense_2_loss_5: 0.0643 - val_dense_2_loss_6: 3.5666e-04 - val_dense_2_loss_7: 0.0406 - val_dense_2_loss_8: 0.0389 - val_dense_2_acc_1: 0.9994 - val_dense_2_acc_2: 0.9953 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 0.9983 - val_dense_2_acc_5: 0.9895 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 0.9947 - val_dense_2_acc_8: 0.9958\n",
      "Epoch 6/1000\n",
      "1000/1000 [==============================] - 246s 246ms/step - loss: 0.1813 - dense_2_loss_1: 0.0050 - dense_2_loss_2: 0.0463 - dense_2_loss_3: 1.9860e-04 - dense_2_loss_4: 0.0115 - dense_2_loss_5: 0.0537 - dense_2_loss_6: 3.1535e-04 - dense_2_loss_7: 0.0328 - dense_2_loss_8: 0.0316 - dense_2_acc_1: 0.9997 - dense_2_acc_2: 0.9965 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 0.9988 - dense_2_acc_5: 0.9902 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 0.9960 - dense_2_acc_8: 0.9972 - val_loss: 0.1474 - val_dense_2_loss_1: 0.0041 - val_dense_2_loss_2: 0.0358 - val_dense_2_loss_3: 1.7064e-04 - val_dense_2_loss_4: 0.0098 - val_dense_2_loss_5: 0.0446 - val_dense_2_loss_6: 2.5948e-04 - val_dense_2_loss_7: 0.0269 - val_dense_2_loss_8: 0.0258 - val_dense_2_acc_1: 0.9997 - val_dense_2_acc_2: 0.9979 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 0.9991 - val_dense_2_acc_5: 0.9911 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 0.9969 - val_dense_2_acc_8: 0.9980\n",
      "Epoch 7/1000\n",
      "1000/1000 [==============================] - 246s 246ms/step - loss: 0.1228 - dense_2_loss_1: 0.0034 - dense_2_loss_2: 0.0296 - dense_2_loss_3: 1.4325e-04 - dense_2_loss_4: 0.0094 - dense_2_loss_5: 0.0380 - dense_2_loss_6: 2.2194e-04 - dense_2_loss_7: 0.0217 - dense_2_loss_8: 0.0202 - dense_2_acc_1: 0.9998 - dense_2_acc_2: 0.9983 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 0.9990 - dense_2_acc_5: 0.9918 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 0.9976 - dense_2_acc_8: 0.9987 - val_loss: 0.1017 - val_dense_2_loss_1: 0.0028 - val_dense_2_loss_2: 0.0245 - val_dense_2_loss_3: 1.2260e-04 - val_dense_2_loss_4: 0.0092 - val_dense_2_loss_5: 0.0319 - val_dense_2_loss_6: 1.9021e-04 - val_dense_2_loss_7: 0.0168 - val_dense_2_loss_8: 0.0162 - val_dense_2_acc_1: 0.9999 - val_dense_2_acc_2: 0.9986 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 0.9990 - val_dense_2_acc_5: 0.9928 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 0.9985 - val_dense_2_acc_8: 0.9991\n",
      "Epoch 8/1000\n",
      "1000/1000 [==============================] - 246s 246ms/step - loss: 0.0869 - dense_2_loss_1: 0.0024 - dense_2_loss_2: 0.0202 - dense_2_loss_3: 1.0370e-04 - dense_2_loss_4: 0.0078 - dense_2_loss_5: 0.0278 - dense_2_loss_6: 1.5702e-04 - dense_2_loss_7: 0.0148 - dense_2_loss_8: 0.0136 - dense_2_acc_1: 0.9999 - dense_2_acc_2: 0.9989 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 0.9991 - dense_2_acc_5: 0.9933 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 0.9986 - dense_2_acc_8: 0.9994 - val_loss: 0.0733 - val_dense_2_loss_1: 0.0022 - val_dense_2_loss_2: 0.0168 - val_dense_2_loss_3: 8.8076e-05 - val_dense_2_loss_4: 0.0066 - val_dense_2_loss_5: 0.0238 - val_dense_2_loss_6: 1.3457e-04 - val_dense_2_loss_7: 0.0120 - val_dense_2_loss_8: 0.0117 - val_dense_2_acc_1: 0.9999 - val_dense_2_acc_2: 0.9991 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 0.9993 - val_dense_2_acc_5: 0.9944 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 0.9990 - val_dense_2_acc_8: 0.9995\n",
      "Epoch 9/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 246s 246ms/step - loss: 0.0627 - dense_2_loss_1: 0.0018 - dense_2_loss_2: 0.0143 - dense_2_loss_3: 7.6454e-05 - dense_2_loss_4: 0.0062 - dense_2_loss_5: 0.0205 - dense_2_loss_6: 1.1466e-04 - dense_2_loss_7: 0.0103 - dense_2_loss_8: 0.0093 - dense_2_acc_1: 0.9999 - dense_2_acc_2: 0.9993 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 0.9993 - dense_2_acc_5: 0.9953 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 0.9992 - dense_2_acc_8: 0.9997 - val_loss: 0.0534 - val_dense_2_loss_1: 0.0016 - val_dense_2_loss_2: 0.0122 - val_dense_2_loss_3: 6.2462e-05 - val_dense_2_loss_4: 0.0054 - val_dense_2_loss_5: 0.0177 - val_dense_2_loss_6: 1.0030e-04 - val_dense_2_loss_7: 0.0088 - val_dense_2_loss_8: 0.0075 - val_dense_2_acc_1: 1.0000 - val_dense_2_acc_2: 0.9995 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 0.9993 - val_dense_2_acc_5: 0.9964 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 0.9993 - val_dense_2_acc_8: 0.9999\n",
      "Epoch 10/1000\n",
      "1000/1000 [==============================] - 245s 245ms/step - loss: 0.0467 - dense_2_loss_1: 0.0014 - dense_2_loss_2: 0.0107 - dense_2_loss_3: 5.5673e-05 - dense_2_loss_4: 0.0050 - dense_2_loss_5: 0.0153 - dense_2_loss_6: 8.6159e-05 - dense_2_loss_7: 0.0074 - dense_2_loss_8: 0.0066 - dense_2_acc_1: 0.9999 - dense_2_acc_2: 0.9994 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 0.9993 - dense_2_acc_5: 0.9970 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 0.9995 - dense_2_acc_8: 0.9999 - val_loss: 0.0410 - val_dense_2_loss_1: 0.0012 - val_dense_2_loss_2: 0.0091 - val_dense_2_loss_3: 5.0007e-05 - val_dense_2_loss_4: 0.0048 - val_dense_2_loss_5: 0.0134 - val_dense_2_loss_6: 7.8990e-05 - val_dense_2_loss_7: 0.0069 - val_dense_2_loss_8: 0.0055 - val_dense_2_acc_1: 1.0000 - val_dense_2_acc_2: 0.9995 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 0.9993 - val_dense_2_acc_5: 0.9975 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 0.9996 - val_dense_2_acc_8: 1.0000\n",
      "Epoch 11/1000\n",
      "1000/1000 [==============================] - 245s 245ms/step - loss: 0.0353 - dense_2_loss_1: 0.0012 - dense_2_loss_2: 0.0084 - dense_2_loss_3: 4.1011e-05 - dense_2_loss_4: 0.0040 - dense_2_loss_5: 0.0113 - dense_2_loss_6: 6.5528e-05 - dense_2_loss_7: 0.0055 - dense_2_loss_8: 0.0048 - dense_2_acc_1: 0.9999 - dense_2_acc_2: 0.9995 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 0.9994 - dense_2_acc_5: 0.9984 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 0.9997 - dense_2_acc_8: 1.0000 - val_loss: 0.0304 - val_dense_2_loss_1: 0.0011 - val_dense_2_loss_2: 0.0075 - val_dense_2_loss_3: 3.4510e-05 - val_dense_2_loss_4: 0.0036 - val_dense_2_loss_5: 0.0094 - val_dense_2_loss_6: 5.4136e-05 - val_dense_2_loss_7: 0.0045 - val_dense_2_loss_8: 0.0042 - val_dense_2_acc_1: 0.9999 - val_dense_2_acc_2: 0.9995 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 0.9993 - val_dense_2_acc_5: 0.9986 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 0.9998 - val_dense_2_acc_8: 1.0000\n",
      "Epoch 12/1000\n",
      "1000/1000 [==============================] - 245s 245ms/step - loss: 0.0266 - dense_2_loss_1: 9.4988e-04 - dense_2_loss_2: 0.0065 - dense_2_loss_3: 2.9619e-05 - dense_2_loss_4: 0.0029 - dense_2_loss_5: 0.0085 - dense_2_loss_6: 4.8690e-05 - dense_2_loss_7: 0.0041 - dense_2_loss_8: 0.0036 - dense_2_acc_1: 0.9999 - dense_2_acc_2: 0.9996 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 0.9996 - dense_2_acc_5: 0.9990 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 0.9999 - dense_2_acc_8: 1.0000 - val_loss: 0.0234 - val_dense_2_loss_1: 9.2423e-04 - val_dense_2_loss_2: 0.0057 - val_dense_2_loss_3: 2.4596e-05 - val_dense_2_loss_4: 0.0026 - val_dense_2_loss_5: 0.0074 - val_dense_2_loss_6: 3.9052e-05 - val_dense_2_loss_7: 0.0037 - val_dense_2_loss_8: 0.0030 - val_dense_2_acc_1: 0.9999 - val_dense_2_acc_2: 0.9997 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 0.9995 - val_dense_2_acc_5: 0.9993 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 1.0000 - val_dense_2_acc_8: 1.0000\n",
      "Epoch 13/1000\n",
      "1000/1000 [==============================] - 245s 245ms/step - loss: 0.0251 - dense_2_loss_1: 0.0013 - dense_2_loss_2: 0.0065 - dense_2_loss_3: 2.0756e-05 - dense_2_loss_4: 0.0023 - dense_2_loss_5: 0.0074 - dense_2_loss_6: 3.7699e-05 - dense_2_loss_7: 0.0040 - dense_2_loss_8: 0.0036 - dense_2_acc_1: 0.9998 - dense_2_acc_2: 0.9992 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 0.9996 - dense_2_acc_5: 0.9992 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 0.9997 - dense_2_acc_8: 0.9997 - val_loss: 0.0191 - val_dense_2_loss_1: 7.4617e-04 - val_dense_2_loss_2: 0.0051 - val_dense_2_loss_3: 1.6697e-05 - val_dense_2_loss_4: 0.0019 - val_dense_2_loss_5: 0.0064 - val_dense_2_loss_6: 3.0490e-05 - val_dense_2_loss_7: 0.0027 - val_dense_2_loss_8: 0.0022 - val_dense_2_acc_1: 0.9999 - val_dense_2_acc_2: 0.9996 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 0.9997 - val_dense_2_acc_5: 0.9996 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 1.0000 - val_dense_2_acc_8: 1.0000\n",
      "Epoch 14/1000\n",
      "1000/1000 [==============================] - 246s 246ms/step - loss: 0.0178 - dense_2_loss_1: 7.1519e-04 - dense_2_loss_2: 0.0048 - dense_2_loss_3: 1.5414e-05 - dense_2_loss_4: 0.0018 - dense_2_loss_5: 0.0057 - dense_2_loss_6: 2.8583e-05 - dense_2_loss_7: 0.0026 - dense_2_loss_8: 0.0021 - dense_2_acc_1: 0.9999 - dense_2_acc_2: 0.9996 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 0.9997 - dense_2_acc_5: 0.9996 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - val_loss: 0.0169 - val_dense_2_loss_1: 6.4665e-04 - val_dense_2_loss_2: 0.0046 - val_dense_2_loss_3: 1.4092e-05 - val_dense_2_loss_4: 0.0018 - val_dense_2_loss_5: 0.0054 - val_dense_2_loss_6: 2.6712e-05 - val_dense_2_loss_7: 0.0024 - val_dense_2_loss_8: 0.0020 - val_dense_2_acc_1: 0.9999 - val_dense_2_acc_2: 0.9995 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 0.9997 - val_dense_2_acc_5: 0.9997 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 1.0000 - val_dense_2_acc_8: 1.0000\n",
      "Epoch 15/1000\n",
      "1000/1000 [==============================] - 245s 245ms/step - loss: 0.0155 - dense_2_loss_1: 6.4593e-04 - dense_2_loss_2: 0.0042 - dense_2_loss_3: 1.2499e-05 - dense_2_loss_4: 0.0016 - dense_2_loss_5: 0.0049 - dense_2_loss_6: 2.2677e-05 - dense_2_loss_7: 0.0023 - dense_2_loss_8: 0.0019 - dense_2_acc_1: 0.9999 - dense_2_acc_2: 0.9996 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 0.9998 - dense_2_acc_5: 0.9998 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - val_loss: 0.0144 - val_dense_2_loss_1: 6.0301e-04 - val_dense_2_loss_2: 0.0039 - val_dense_2_loss_3: 1.0628e-05 - val_dense_2_loss_4: 0.0014 - val_dense_2_loss_5: 0.0044 - val_dense_2_loss_6: 1.8901e-05 - val_dense_2_loss_7: 0.0021 - val_dense_2_loss_8: 0.0018 - val_dense_2_acc_1: 1.0000 - val_dense_2_acc_2: 0.9997 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 0.9999 - val_dense_2_acc_5: 0.9999 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 1.0000 - val_dense_2_acc_8: 1.0000\n",
      "Epoch 16/1000\n",
      "1000/1000 [==============================] - 245s 245ms/step - loss: 0.0135 - dense_2_loss_1: 5.8570e-04 - dense_2_loss_2: 0.0038 - dense_2_loss_3: 9.7540e-06 - dense_2_loss_4: 0.0013 - dense_2_loss_5: 0.0042 - dense_2_loss_6: 1.7907e-05 - dense_2_loss_7: 0.0019 - dense_2_loss_8: 0.0016 - dense_2_acc_1: 0.9999 - dense_2_acc_2: 0.9996 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 0.9999 - dense_2_acc_5: 0.9999 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - val_loss: 0.0126 - val_dense_2_loss_1: 6.1543e-04 - val_dense_2_loss_2: 0.0037 - val_dense_2_loss_3: 8.5611e-06 - val_dense_2_loss_4: 0.0013 - val_dense_2_loss_5: 0.0036 - val_dense_2_loss_6: 1.6295e-05 - val_dense_2_loss_7: 0.0018 - val_dense_2_loss_8: 0.0015 - val_dense_2_acc_1: 0.9999 - val_dense_2_acc_2: 0.9996 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 0.9999 - val_dense_2_acc_5: 1.0000 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 1.0000 - val_dense_2_acc_8: 1.0000\n",
      "Epoch 17/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 245s 245ms/step - loss: 0.0114 - dense_2_loss_1: 5.1393e-04 - dense_2_loss_2: 0.0033 - dense_2_loss_3: 7.6580e-06 - dense_2_loss_4: 0.0011 - dense_2_loss_5: 0.0034 - dense_2_loss_6: 1.4462e-05 - dense_2_loss_7: 0.0017 - dense_2_loss_8: 0.0014 - dense_2_acc_1: 0.9999 - dense_2_acc_2: 0.9997 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 0.9999 - dense_2_acc_5: 0.9999 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - val_loss: 0.0105 - val_dense_2_loss_1: 5.2986e-04 - val_dense_2_loss_2: 0.0032 - val_dense_2_loss_3: 6.7855e-06 - val_dense_2_loss_4: 8.9261e-04 - val_dense_2_loss_5: 0.0031 - val_dense_2_loss_6: 1.2488e-05 - val_dense_2_loss_7: 0.0014 - val_dense_2_loss_8: 0.0013 - val_dense_2_acc_1: 0.9999 - val_dense_2_acc_2: 0.9997 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 1.0000 - val_dense_2_acc_5: 1.0000 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 1.0000 - val_dense_2_acc_8: 1.0000\n",
      "Epoch 18/1000\n",
      "1000/1000 [==============================] - 245s 245ms/step - loss: 0.0105 - dense_2_loss_1: 6.4784e-04 - dense_2_loss_2: 0.0032 - dense_2_loss_3: 5.6844e-06 - dense_2_loss_4: 9.2155e-04 - dense_2_loss_5: 0.0029 - dense_2_loss_6: 1.1628e-05 - dense_2_loss_7: 0.0014 - dense_2_loss_8: 0.0014 - dense_2_acc_1: 0.9999 - dense_2_acc_2: 0.9996 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 0.9999 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 0.9999 - val_loss: 0.0094 - val_dense_2_loss_1: 5.4108e-04 - val_dense_2_loss_2: 0.0029 - val_dense_2_loss_3: 5.1388e-06 - val_dense_2_loss_4: 8.5587e-04 - val_dense_2_loss_5: 0.0027 - val_dense_2_loss_6: 9.5088e-06 - val_dense_2_loss_7: 0.0013 - val_dense_2_loss_8: 0.0011 - val_dense_2_acc_1: 0.9999 - val_dense_2_acc_2: 0.9997 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 0.9999 - val_dense_2_acc_5: 1.0000 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 1.0000 - val_dense_2_acc_8: 1.0000\n",
      "Epoch 19/1000\n",
      "1000/1000 [==============================] - 246s 246ms/step - loss: 0.0085 - dense_2_loss_1: 4.5805e-04 - dense_2_loss_2: 0.0027 - dense_2_loss_3: 4.6268e-06 - dense_2_loss_4: 7.6451e-04 - dense_2_loss_5: 0.0024 - dense_2_loss_6: 8.9630e-06 - dense_2_loss_7: 0.0012 - dense_2_loss_8: 9.9001e-04 - dense_2_acc_1: 0.9999 - dense_2_acc_2: 0.9997 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - val_loss: 0.0076 - val_dense_2_loss_1: 3.6817e-04 - val_dense_2_loss_2: 0.0023 - val_dense_2_loss_3: 3.9916e-06 - val_dense_2_loss_4: 6.6143e-04 - val_dense_2_loss_5: 0.0022 - val_dense_2_loss_6: 7.7661e-06 - val_dense_2_loss_7: 0.0011 - val_dense_2_loss_8: 9.2480e-04 - val_dense_2_acc_1: 1.0000 - val_dense_2_acc_2: 0.9998 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 1.0000 - val_dense_2_acc_5: 1.0000 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 1.0000 - val_dense_2_acc_8: 1.0000\n",
      "Epoch 20/1000\n",
      "1000/1000 [==============================] - 246s 246ms/step - loss: 0.0075 - dense_2_loss_1: 4.2801e-04 - dense_2_loss_2: 0.0025 - dense_2_loss_3: 3.7552e-06 - dense_2_loss_4: 6.4468e-04 - dense_2_loss_5: 0.0021 - dense_2_loss_6: 7.4776e-06 - dense_2_loss_7: 0.0010 - dense_2_loss_8: 8.6812e-04 - dense_2_acc_1: 0.9999 - dense_2_acc_2: 0.9997 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - val_loss: 0.0069 - val_dense_2_loss_1: 4.3603e-04 - val_dense_2_loss_2: 0.0023 - val_dense_2_loss_3: 3.2816e-06 - val_dense_2_loss_4: 5.7720e-04 - val_dense_2_loss_5: 0.0018 - val_dense_2_loss_6: 6.8535e-06 - val_dense_2_loss_7: 9.0320e-04 - val_dense_2_loss_8: 7.9329e-04 - val_dense_2_acc_1: 0.9999 - val_dense_2_acc_2: 0.9997 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 1.0000 - val_dense_2_acc_5: 1.0000 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 1.0000 - val_dense_2_acc_8: 1.0000\n",
      "Epoch 21/1000\n",
      "1000/1000 [==============================] - 246s 246ms/step - loss: 0.0065 - dense_2_loss_1: 3.9362e-04 - dense_2_loss_2: 0.0023 - dense_2_loss_3: 3.0798e-06 - dense_2_loss_4: 5.4489e-04 - dense_2_loss_5: 0.0017 - dense_2_loss_6: 6.1253e-06 - dense_2_loss_7: 8.4577e-04 - dense_2_loss_8: 7.4637e-04 - dense_2_acc_1: 0.9999 - dense_2_acc_2: 0.9997 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - val_loss: 0.0061 - val_dense_2_loss_1: 3.3227e-04 - val_dense_2_loss_2: 0.0022 - val_dense_2_loss_3: 2.8327e-06 - val_dense_2_loss_4: 4.8830e-04 - val_dense_2_loss_5: 0.0016 - val_dense_2_loss_6: 5.4082e-06 - val_dense_2_loss_7: 7.7469e-04 - val_dense_2_loss_8: 6.9051e-04 - val_dense_2_acc_1: 1.0000 - val_dense_2_acc_2: 0.9996 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 1.0000 - val_dense_2_acc_5: 1.0000 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 1.0000 - val_dense_2_acc_8: 1.0000\n",
      "Epoch 22/1000\n",
      "1000/1000 [==============================] - 245s 245ms/step - loss: 0.0065 - dense_2_loss_1: 3.7040e-04 - dense_2_loss_2: 0.0021 - dense_2_loss_3: 2.3977e-06 - dense_2_loss_4: 4.7216e-04 - dense_2_loss_5: 0.0015 - dense_2_loss_6: 5.3211e-06 - dense_2_loss_7: 9.2692e-04 - dense_2_loss_8: 0.0011 - dense_2_acc_1: 0.9999 - dense_2_acc_2: 0.9997 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 0.9999 - dense_2_acc_8: 0.9999 - val_loss: 0.0054 - val_dense_2_loss_1: 2.9890e-04 - val_dense_2_loss_2: 0.0020 - val_dense_2_loss_3: 2.2879e-06 - val_dense_2_loss_4: 4.9022e-04 - val_dense_2_loss_5: 0.0014 - val_dense_2_loss_6: 4.5260e-06 - val_dense_2_loss_7: 6.6778e-04 - val_dense_2_loss_8: 5.8198e-04 - val_dense_2_acc_1: 0.9999 - val_dense_2_acc_2: 0.9996 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 1.0000 - val_dense_2_acc_5: 1.0000 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 1.0000 - val_dense_2_acc_8: 1.0000\n",
      "Epoch 23/1000\n",
      "1000/1000 [==============================] - 246s 246ms/step - loss: 0.0052 - dense_2_loss_1: 3.4442e-04 - dense_2_loss_2: 0.0019 - dense_2_loss_3: 2.0775e-06 - dense_2_loss_4: 4.2435e-04 - dense_2_loss_5: 0.0014 - dense_2_loss_6: 4.4855e-06 - dense_2_loss_7: 6.5301e-04 - dense_2_loss_8: 5.7021e-04 - dense_2_acc_1: 0.9999 - dense_2_acc_2: 0.9997 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - val_loss: 0.0052 - val_dense_2_loss_1: 3.6109e-04 - val_dense_2_loss_2: 0.0019 - val_dense_2_loss_3: 1.8845e-06 - val_dense_2_loss_4: 4.2507e-04 - val_dense_2_loss_5: 0.0013 - val_dense_2_loss_6: 3.9600e-06 - val_dense_2_loss_7: 6.3413e-04 - val_dense_2_loss_8: 5.4345e-04 - val_dense_2_acc_1: 0.9999 - val_dense_2_acc_2: 0.9996 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 1.0000 - val_dense_2_acc_5: 1.0000 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 1.0000 - val_dense_2_acc_8: 1.0000\n",
      "Epoch 24/1000\n",
      "1000/1000 [==============================] - 245s 245ms/step - loss: 0.0048 - dense_2_loss_1: 3.2907e-04 - dense_2_loss_2: 0.0018 - dense_2_loss_3: 1.7667e-06 - dense_2_loss_4: 3.9221e-04 - dense_2_loss_5: 0.0012 - dense_2_loss_6: 3.6855e-06 - dense_2_loss_7: 5.9997e-04 - dense_2_loss_8: 5.3559e-04 - dense_2_acc_1: 0.9999 - dense_2_acc_2: 0.9997 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - val_loss: 0.0048 - val_dense_2_loss_1: 4.0208e-04 - val_dense_2_loss_2: 0.0018 - val_dense_2_loss_3: 1.6145e-06 - val_dense_2_loss_4: 3.6056e-04 - val_dense_2_loss_5: 0.0011 - val_dense_2_loss_6: 3.3452e-06 - val_dense_2_loss_7: 5.9415e-04 - val_dense_2_loss_8: 5.0020e-04 - val_dense_2_acc_1: 0.9999 - val_dense_2_acc_2: 0.9996 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 1.0000 - val_dense_2_acc_5: 1.0000 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 1.0000 - val_dense_2_acc_8: 1.0000\n",
      "Epoch 25/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 246s 246ms/step - loss: 0.0045 - dense_2_loss_1: 3.3013e-04 - dense_2_loss_2: 0.0017 - dense_2_loss_3: 1.5270e-06 - dense_2_loss_4: 3.5974e-04 - dense_2_loss_5: 0.0011 - dense_2_loss_6: 3.2074e-06 - dense_2_loss_7: 5.4418e-04 - dense_2_loss_8: 4.9559e-04 - dense_2_acc_1: 0.9999 - dense_2_acc_2: 0.9997 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - val_loss: 0.0043 - val_dense_2_loss_1: 3.0702e-04 - val_dense_2_loss_2: 0.0017 - val_dense_2_loss_3: 1.4040e-06 - val_dense_2_loss_4: 3.4709e-04 - val_dense_2_loss_5: 0.0010 - val_dense_2_loss_6: 3.1554e-06 - val_dense_2_loss_7: 4.9766e-04 - val_dense_2_loss_8: 4.5854e-04 - val_dense_2_acc_1: 0.9999 - val_dense_2_acc_2: 0.9996 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 1.0000 - val_dense_2_acc_5: 1.0000 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 1.0000 - val_dense_2_acc_8: 1.0000\n",
      "Epoch 26/1000\n",
      "1000/1000 [==============================] - 245s 245ms/step - loss: 0.0041 - dense_2_loss_1: 3.0151e-04 - dense_2_loss_2: 0.0016 - dense_2_loss_3: 1.2981e-06 - dense_2_loss_4: 3.1085e-04 - dense_2_loss_5: 9.6477e-04 - dense_2_loss_6: 2.8175e-06 - dense_2_loss_7: 4.8944e-04 - dense_2_loss_8: 4.4754e-04 - dense_2_acc_1: 0.9999 - dense_2_acc_2: 0.9997 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - val_loss: 0.0039 - val_dense_2_loss_1: 3.1947e-04 - val_dense_2_loss_2: 0.0015 - val_dense_2_loss_3: 1.1824e-06 - val_dense_2_loss_4: 2.8454e-04 - val_dense_2_loss_5: 9.1467e-04 - val_dense_2_loss_6: 2.5786e-06 - val_dense_2_loss_7: 4.6016e-04 - val_dense_2_loss_8: 4.1666e-04 - val_dense_2_acc_1: 0.9999 - val_dense_2_acc_2: 0.9997 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 1.0000 - val_dense_2_acc_5: 1.0000 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 1.0000 - val_dense_2_acc_8: 1.0000\n",
      "Epoch 27/1000\n",
      "1000/1000 [==============================] - 245s 245ms/step - loss: 0.0038 - dense_2_loss_1: 2.5777e-04 - dense_2_loss_2: 0.0015 - dense_2_loss_3: 1.1142e-06 - dense_2_loss_4: 2.8192e-04 - dense_2_loss_5: 8.5431e-04 - dense_2_loss_6: 2.4742e-06 - dense_2_loss_7: 4.7440e-04 - dense_2_loss_8: 4.9966e-04 - dense_2_acc_1: 0.9999 - dense_2_acc_2: 0.9997 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - val_loss: 0.0053 - val_dense_2_loss_1: 2.0449e-04 - val_dense_2_loss_2: 0.0012 - val_dense_2_loss_3: 8.2862e-07 - val_dense_2_loss_4: 2.5521e-04 - val_dense_2_loss_5: 0.0010 - val_dense_2_loss_6: 2.4742e-06 - val_dense_2_loss_7: 0.0014 - val_dense_2_loss_8: 0.0012 - val_dense_2_acc_1: 1.0000 - val_dense_2_acc_2: 0.9999 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 1.0000 - val_dense_2_acc_5: 1.0000 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 0.9998 - val_dense_2_acc_8: 1.0000\n",
      "Epoch 28/1000\n",
      "1000/1000 [==============================] - 246s 246ms/step - loss: 0.0034 - dense_2_loss_1: 2.3958e-04 - dense_2_loss_2: 0.0013 - dense_2_loss_3: 9.5153e-07 - dense_2_loss_4: 2.5391e-04 - dense_2_loss_5: 8.0298e-04 - dense_2_loss_6: 2.1254e-06 - dense_2_loss_7: 4.2101e-04 - dense_2_loss_8: 3.9699e-04 - dense_2_acc_1: 0.9999 - dense_2_acc_2: 0.9997 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - val_loss: 0.0031 - val_dense_2_loss_1: 2.3307e-04 - val_dense_2_loss_2: 0.0012 - val_dense_2_loss_3: 9.4041e-07 - val_dense_2_loss_4: 2.6218e-04 - val_dense_2_loss_5: 7.5435e-04 - val_dense_2_loss_6: 2.0161e-06 - val_dense_2_loss_7: 3.6487e-04 - val_dense_2_loss_8: 3.2390e-04 - val_dense_2_acc_1: 0.9999 - val_dense_2_acc_2: 0.9998 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 1.0000 - val_dense_2_acc_5: 1.0000 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 1.0000 - val_dense_2_acc_8: 1.0000\n",
      "Epoch 29/1000\n",
      "1000/1000 [==============================] - 245s 245ms/step - loss: 0.0031 - dense_2_loss_1: 2.1946e-04 - dense_2_loss_2: 0.0012 - dense_2_loss_3: 8.7943e-07 - dense_2_loss_4: 2.3983e-04 - dense_2_loss_5: 7.1560e-04 - dense_2_loss_6: 1.9129e-06 - dense_2_loss_7: 3.5315e-04 - dense_2_loss_8: 3.2085e-04 - dense_2_acc_1: 0.9999 - dense_2_acc_2: 0.9998 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - val_loss: 0.0031 - val_dense_2_loss_1: 2.8353e-04 - val_dense_2_loss_2: 0.0013 - val_dense_2_loss_3: 8.1594e-07 - val_dense_2_loss_4: 2.2264e-04 - val_dense_2_loss_5: 7.0311e-04 - val_dense_2_loss_6: 2.0327e-06 - val_dense_2_loss_7: 3.4019e-04 - val_dense_2_loss_8: 3.0627e-04 - val_dense_2_acc_1: 0.9999 - val_dense_2_acc_2: 0.9998 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 1.0000 - val_dense_2_acc_5: 1.0000 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 1.0000 - val_dense_2_acc_8: 1.0000\n",
      "Epoch 30/1000\n",
      "1000/1000 [==============================] - 246s 246ms/step - loss: 0.0029 - dense_2_loss_1: 2.3227e-04 - dense_2_loss_2: 0.0012 - dense_2_loss_3: 7.7556e-07 - dense_2_loss_4: 2.1845e-04 - dense_2_loss_5: 6.5276e-04 - dense_2_loss_6: 1.7405e-06 - dense_2_loss_7: 3.2619e-04 - dense_2_loss_8: 3.0342e-04 - dense_2_acc_1: 0.9999 - dense_2_acc_2: 0.9998 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - val_loss: 0.0029 - val_dense_2_loss_1: 2.5189e-04 - val_dense_2_loss_2: 0.0012 - val_dense_2_loss_3: 7.4491e-07 - val_dense_2_loss_4: 2.0887e-04 - val_dense_2_loss_5: 6.2895e-04 - val_dense_2_loss_6: 1.6352e-06 - val_dense_2_loss_7: 3.1021e-04 - val_dense_2_loss_8: 2.9007e-04 - val_dense_2_acc_1: 0.9999 - val_dense_2_acc_2: 0.9998 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 1.0000 - val_dense_2_acc_5: 1.0000 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 1.0000 - val_dense_2_acc_8: 1.0000\n",
      "Epoch 31/1000\n",
      "1000/1000 [==============================] - 246s 246ms/step - loss: 0.0027 - dense_2_loss_1: 2.1551e-04 - dense_2_loss_2: 0.0011 - dense_2_loss_3: 7.0395e-07 - dense_2_loss_4: 2.0198e-04 - dense_2_loss_5: 5.8621e-04 - dense_2_loss_6: 1.5883e-06 - dense_2_loss_7: 3.0146e-04 - dense_2_loss_8: 2.8228e-04 - dense_2_acc_1: 0.9999 - dense_2_acc_2: 0.9998 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - val_loss: 0.0027 - val_dense_2_loss_1: 2.1149e-04 - val_dense_2_loss_2: 0.0012 - val_dense_2_loss_3: 6.5124e-07 - val_dense_2_loss_4: 1.8726e-04 - val_dense_2_loss_5: 5.6484e-04 - val_dense_2_loss_6: 1.2948e-06 - val_dense_2_loss_7: 2.8341e-04 - val_dense_2_loss_8: 2.7278e-04 - val_dense_2_acc_1: 1.0000 - val_dense_2_acc_2: 0.9998 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 1.0000 - val_dense_2_acc_5: 1.0000 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 1.0000 - val_dense_2_acc_8: 1.0000\n",
      "Epoch 32/1000\n",
      "1000/1000 [==============================] - 245s 245ms/step - loss: 0.0026 - dense_2_loss_1: 2.3639e-04 - dense_2_loss_2: 0.0011 - dense_2_loss_3: 6.2427e-07 - dense_2_loss_4: 1.7892e-04 - dense_2_loss_5: 5.3122e-04 - dense_2_loss_6: 1.3662e-06 - dense_2_loss_7: 2.7070e-04 - dense_2_loss_8: 2.5506e-04 - dense_2_acc_1: 0.9999 - dense_2_acc_2: 0.9998 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - val_loss: 0.0023 - val_dense_2_loss_1: 1.7066e-04 - val_dense_2_loss_2: 9.4395e-04 - val_dense_2_loss_3: 5.9286e-07 - val_dense_2_loss_4: 1.6816e-04 - val_dense_2_loss_5: 5.0380e-04 - val_dense_2_loss_6: 1.3030e-06 - val_dense_2_loss_7: 2.6070e-04 - val_dense_2_loss_8: 2.4133e-04 - val_dense_2_acc_1: 1.0000 - val_dense_2_acc_2: 0.9998 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 1.0000 - val_dense_2_acc_5: 1.0000 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 1.0000 - val_dense_2_acc_8: 1.0000\n",
      "Epoch 33/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 245s 245ms/step - loss: 0.0029 - dense_2_loss_1: 2.1230e-04 - dense_2_loss_2: 0.0010 - dense_2_loss_3: 5.6552e-07 - dense_2_loss_4: 1.6669e-04 - dense_2_loss_5: 4.9267e-04 - dense_2_loss_6: 1.2964e-06 - dense_2_loss_7: 5.1637e-04 - dense_2_loss_8: 4.3676e-04 - dense_2_acc_1: 0.9999 - dense_2_acc_2: 0.9998 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 0.9999 - dense_2_acc_8: 0.9999 - val_loss: 0.0027 - val_dense_2_loss_1: 3.3717e-04 - val_dense_2_loss_2: 0.0012 - val_dense_2_loss_3: 4.7762e-07 - val_dense_2_loss_4: 1.5979e-04 - val_dense_2_loss_5: 5.1907e-04 - val_dense_2_loss_6: 1.5057e-06 - val_dense_2_loss_7: 2.7978e-04 - val_dense_2_loss_8: 2.7953e-04 - val_dense_2_acc_1: 0.9999 - val_dense_2_acc_2: 0.9998 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 1.0000 - val_dense_2_acc_5: 1.0000 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 1.0000 - val_dense_2_acc_8: 1.0000\n",
      "Epoch 34/1000\n",
      "1000/1000 [==============================] - 246s 246ms/step - loss: 0.0023 - dense_2_loss_1: 2.3083e-04 - dense_2_loss_2: 9.8425e-04 - dense_2_loss_3: 4.9139e-07 - dense_2_loss_4: 1.5311e-04 - dense_2_loss_5: 4.6243e-04 - dense_2_loss_6: 1.1973e-06 - dense_2_loss_7: 2.3391e-04 - dense_2_loss_8: 2.0457e-04 - dense_2_acc_1: 0.9999 - dense_2_acc_2: 0.9998 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - val_loss: 0.0022 - val_dense_2_loss_1: 2.4063e-04 - val_dense_2_loss_2: 9.5105e-04 - val_dense_2_loss_3: 4.5487e-07 - val_dense_2_loss_4: 1.4752e-04 - val_dense_2_loss_5: 4.5204e-04 - val_dense_2_loss_6: 1.1346e-06 - val_dense_2_loss_7: 2.1415e-04 - val_dense_2_loss_8: 1.9126e-04 - val_dense_2_acc_1: 0.9999 - val_dense_2_acc_2: 0.9998 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 1.0000 - val_dense_2_acc_5: 1.0000 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 1.0000 - val_dense_2_acc_8: 1.0000\n",
      "Epoch 35/1000\n",
      "1000/1000 [==============================] - 245s 245ms/step - loss: 0.0021 - dense_2_loss_1: 1.8441e-04 - dense_2_loss_2: 9.2121e-04 - dense_2_loss_3: 4.7019e-07 - dense_2_loss_4: 1.4659e-04 - dense_2_loss_5: 4.4015e-04 - dense_2_loss_6: 1.0985e-06 - dense_2_loss_7: 2.1436e-04 - dense_2_loss_8: 1.9218e-04 - dense_2_acc_1: 1.0000 - dense_2_acc_2: 0.9998 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - val_loss: 0.0021 - val_dense_2_loss_1: 2.2769e-04 - val_dense_2_loss_2: 8.9003e-04 - val_dense_2_loss_3: 4.3165e-07 - val_dense_2_loss_4: 1.4336e-04 - val_dense_2_loss_5: 4.2719e-04 - val_dense_2_loss_6: 1.1176e-06 - val_dense_2_loss_7: 2.1600e-04 - val_dense_2_loss_8: 1.9253e-04 - val_dense_2_acc_1: 0.9999 - val_dense_2_acc_2: 0.9999 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 1.0000 - val_dense_2_acc_5: 1.0000 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 1.0000 - val_dense_2_acc_8: 1.0000\n",
      "Epoch 36/1000\n",
      "1000/1000 [==============================] - 246s 246ms/step - loss: 0.0020 - dense_2_loss_1: 1.9944e-04 - dense_2_loss_2: 8.9911e-04 - dense_2_loss_3: 4.4143e-07 - dense_2_loss_4: 1.4262e-04 - dense_2_loss_5: 4.0939e-04 - dense_2_loss_6: 9.9376e-07 - dense_2_loss_7: 2.0635e-04 - dense_2_loss_8: 1.8915e-04 - dense_2_acc_1: 0.9999 - dense_2_acc_2: 0.9998 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - val_loss: 0.0022 - val_dense_2_loss_1: 2.3449e-04 - val_dense_2_loss_2: 0.0010 - val_dense_2_loss_3: 4.4863e-07 - val_dense_2_loss_4: 1.4631e-04 - val_dense_2_loss_5: 3.9915e-04 - val_dense_2_loss_6: 9.2895e-07 - val_dense_2_loss_7: 2.0457e-04 - val_dense_2_loss_8: 1.8388e-04 - val_dense_2_acc_1: 0.9999 - val_dense_2_acc_2: 0.9997 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 1.0000 - val_dense_2_acc_5: 1.0000 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 1.0000 - val_dense_2_acc_8: 1.0000\n",
      "Epoch 37/1000\n",
      "1000/1000 [==============================] - 245s 245ms/step - loss: 0.0020 - dense_2_loss_1: 2.1066e-04 - dense_2_loss_2: 8.8612e-04 - dense_2_loss_3: 4.2391e-07 - dense_2_loss_4: 1.3593e-04 - dense_2_loss_5: 3.9097e-04 - dense_2_loss_6: 9.4346e-07 - dense_2_loss_7: 1.9875e-04 - dense_2_loss_8: 1.8430e-04 - dense_2_acc_1: 0.9999 - dense_2_acc_2: 0.9998 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - val_loss: 0.0019 - val_dense_2_loss_1: 1.7380e-04 - val_dense_2_loss_2: 8.0003e-04 - val_dense_2_loss_3: 3.9628e-07 - val_dense_2_loss_4: 1.3395e-04 - val_dense_2_loss_5: 3.6993e-04 - val_dense_2_loss_6: 1.0694e-06 - val_dense_2_loss_7: 1.9459e-04 - val_dense_2_loss_8: 1.7917e-04 - val_dense_2_acc_1: 1.0000 - val_dense_2_acc_2: 0.9999 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 1.0000 - val_dense_2_acc_5: 1.0000 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 1.0000 - val_dense_2_acc_8: 1.0000\n",
      "Epoch 38/1000\n",
      "1000/1000 [==============================] - 245s 245ms/step - loss: 0.0019 - dense_2_loss_1: 1.8174e-04 - dense_2_loss_2: 8.5401e-04 - dense_2_loss_3: 3.8843e-07 - dense_2_loss_4: 1.2621e-04 - dense_2_loss_5: 3.6608e-04 - dense_2_loss_6: 8.8565e-07 - dense_2_loss_7: 1.8927e-04 - dense_2_loss_8: 1.7484e-04 - dense_2_acc_1: 0.9999 - dense_2_acc_2: 0.9998 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - val_loss: 0.0019 - val_dense_2_loss_1: 1.9208e-04 - val_dense_2_loss_2: 8.4928e-04 - val_dense_2_loss_3: 3.6996e-07 - val_dense_2_loss_4: 1.1967e-04 - val_dense_2_loss_5: 3.5042e-04 - val_dense_2_loss_6: 9.1740e-07 - val_dense_2_loss_7: 1.8627e-04 - val_dense_2_loss_8: 1.6342e-04 - val_dense_2_acc_1: 0.9999 - val_dense_2_acc_2: 0.9999 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 1.0000 - val_dense_2_acc_5: 1.0000 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 1.0000 - val_dense_2_acc_8: 1.0000\n",
      "Epoch 39/1000\n",
      "1000/1000 [==============================] - 246s 246ms/step - loss: 0.0019 - dense_2_loss_1: 1.6927e-04 - dense_2_loss_2: 8.6899e-04 - dense_2_loss_3: 3.6454e-07 - dense_2_loss_4: 1.2160e-04 - dense_2_loss_5: 3.5597e-04 - dense_2_loss_6: 8.7820e-07 - dense_2_loss_7: 1.8808e-04 - dense_2_loss_8: 2.2394e-04 - dense_2_acc_1: 1.0000 - dense_2_acc_2: 0.9998 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - val_loss: 0.0018 - val_dense_2_loss_1: 1.2451e-04 - val_dense_2_loss_2: 8.4744e-04 - val_dense_2_loss_3: 3.4187e-07 - val_dense_2_loss_4: 1.1878e-04 - val_dense_2_loss_5: 3.4230e-04 - val_dense_2_loss_6: 7.3371e-07 - val_dense_2_loss_7: 1.6919e-04 - val_dense_2_loss_8: 1.6057e-04 - val_dense_2_acc_1: 1.0000 - val_dense_2_acc_2: 0.9998 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 1.0000 - val_dense_2_acc_5: 1.0000 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 1.0000 - val_dense_2_acc_8: 1.0000\n",
      "Epoch 40/1000\n",
      "1000/1000 [==============================] - 246s 246ms/step - loss: 0.0016 - dense_2_loss_1: 1.5661e-04 - dense_2_loss_2: 7.3250e-04 - dense_2_loss_3: 3.3302e-07 - dense_2_loss_4: 1.1324e-04 - dense_2_loss_5: 3.2530e-04 - dense_2_loss_6: 7.7389e-07 - dense_2_loss_7: 1.6607e-04 - dense_2_loss_8: 1.4841e-04 - dense_2_acc_1: 1.0000 - dense_2_acc_2: 0.9999 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - val_loss: 0.0018 - val_dense_2_loss_1: 2.2455e-04 - val_dense_2_loss_2: 8.3680e-04 - val_dense_2_loss_3: 3.2115e-07 - val_dense_2_loss_4: 1.1484e-04 - val_dense_2_loss_5: 3.1425e-04 - val_dense_2_loss_6: 8.1398e-07 - val_dense_2_loss_7: 1.6589e-04 - val_dense_2_loss_8: 1.4824e-04 - val_dense_2_acc_1: 0.9999 - val_dense_2_acc_2: 0.9998 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 1.0000 - val_dense_2_acc_5: 1.0000 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 1.0000 - val_dense_2_acc_8: 1.0000\n",
      "Epoch 41/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 246s 246ms/step - loss: 0.0017 - dense_2_loss_1: 1.9977e-04 - dense_2_loss_2: 7.8147e-04 - dense_2_loss_3: 3.3130e-07 - dense_2_loss_4: 1.0890e-04 - dense_2_loss_5: 3.0797e-04 - dense_2_loss_6: 7.7325e-07 - dense_2_loss_7: 1.5713e-04 - dense_2_loss_8: 1.4308e-04 - dense_2_acc_1: 0.9999 - dense_2_acc_2: 0.9998 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - val_loss: 0.0018 - val_dense_2_loss_1: 1.9727e-04 - val_dense_2_loss_2: 8.5911e-04 - val_dense_2_loss_3: 3.1898e-07 - val_dense_2_loss_4: 1.0732e-04 - val_dense_2_loss_5: 2.9617e-04 - val_dense_2_loss_6: 9.0698e-07 - val_dense_2_loss_7: 1.5501e-04 - val_dense_2_loss_8: 1.4391e-04 - val_dense_2_acc_1: 1.0000 - val_dense_2_acc_2: 0.9998 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 1.0000 - val_dense_2_acc_5: 1.0000 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 1.0000 - val_dense_2_acc_8: 1.0000\n",
      "Epoch 42/1000\n",
      "1000/1000 [==============================] - 245s 245ms/step - loss: 0.0015 - dense_2_loss_1: 1.4754e-04 - dense_2_loss_2: 6.9906e-04 - dense_2_loss_3: 3.1951e-07 - dense_2_loss_4: 1.0053e-04 - dense_2_loss_5: 2.8821e-04 - dense_2_loss_6: 7.1624e-07 - dense_2_loss_7: 1.5097e-04 - dense_2_loss_8: 1.3915e-04 - dense_2_acc_1: 1.0000 - dense_2_acc_2: 0.9999 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - val_loss: 0.0017 - val_dense_2_loss_1: 1.9327e-04 - val_dense_2_loss_2: 8.0358e-04 - val_dense_2_loss_3: 3.1770e-07 - val_dense_2_loss_4: 9.3927e-05 - val_dense_2_loss_5: 2.8606e-04 - val_dense_2_loss_6: 6.4827e-07 - val_dense_2_loss_7: 1.4345e-04 - val_dense_2_loss_8: 1.4048e-04 - val_dense_2_acc_1: 0.9999 - val_dense_2_acc_2: 0.9997 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 1.0000 - val_dense_2_acc_5: 1.0000 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 1.0000 - val_dense_2_acc_8: 1.0000\n",
      "Epoch 43/1000\n",
      "1000/1000 [==============================] - 246s 246ms/step - loss: 0.0015 - dense_2_loss_1: 1.5610e-04 - dense_2_loss_2: 7.2709e-04 - dense_2_loss_3: 3.0230e-07 - dense_2_loss_4: 9.5288e-05 - dense_2_loss_5: 2.6701e-04 - dense_2_loss_6: 7.3989e-07 - dense_2_loss_7: 1.4111e-04 - dense_2_loss_8: 1.3271e-04 - dense_2_acc_1: 0.9999 - dense_2_acc_2: 0.9998 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - val_loss: 0.0014 - val_dense_2_loss_1: 1.6317e-04 - val_dense_2_loss_2: 6.2211e-04 - val_dense_2_loss_3: 2.8157e-07 - val_dense_2_loss_4: 8.9711e-05 - val_dense_2_loss_5: 2.5840e-04 - val_dense_2_loss_6: 8.3000e-07 - val_dense_2_loss_7: 1.3402e-04 - val_dense_2_loss_8: 1.2746e-04 - val_dense_2_acc_1: 0.9999 - val_dense_2_acc_2: 0.9999 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 1.0000 - val_dense_2_acc_5: 1.0000 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 1.0000 - val_dense_2_acc_8: 1.0000\n",
      "Epoch 44/1000\n",
      "1000/1000 [==============================] - 245s 245ms/step - loss: 0.0014 - dense_2_loss_1: 1.4810e-04 - dense_2_loss_2: 6.8833e-04 - dense_2_loss_3: 3.0089e-07 - dense_2_loss_4: 9.0530e-05 - dense_2_loss_5: 2.5231e-04 - dense_2_loss_6: 7.3143e-07 - dense_2_loss_7: 1.3182e-04 - dense_2_loss_8: 1.2573e-04 - dense_2_acc_1: 1.0000 - dense_2_acc_2: 0.9998 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - val_loss: 0.0013 - val_dense_2_loss_1: 1.1530e-04 - val_dense_2_loss_2: 6.5971e-04 - val_dense_2_loss_3: 2.9865e-07 - val_dense_2_loss_4: 8.1328e-05 - val_dense_2_loss_5: 2.4142e-04 - val_dense_2_loss_6: 8.6789e-07 - val_dense_2_loss_7: 1.2851e-04 - val_dense_2_loss_8: 1.1922e-04 - val_dense_2_acc_1: 1.0000 - val_dense_2_acc_2: 0.9999 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 1.0000 - val_dense_2_acc_5: 1.0000 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 1.0000 - val_dense_2_acc_8: 1.0000\n",
      "Epoch 45/1000\n",
      "1000/1000 [==============================] - 246s 246ms/step - loss: 0.0019 - dense_2_loss_1: 2.5284e-04 - dense_2_loss_2: 7.4093e-04 - dense_2_loss_3: 2.6729e-07 - dense_2_loss_4: 8.5790e-05 - dense_2_loss_5: 2.5419e-04 - dense_2_loss_6: 6.2372e-07 - dense_2_loss_7: 2.8821e-04 - dense_2_loss_8: 2.8068e-04 - dense_2_acc_1: 0.9999 - dense_2_acc_2: 0.9998 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 0.9999 - dense_2_acc_8: 0.9999 - val_loss: 0.0013 - val_dense_2_loss_1: 1.2475e-04 - val_dense_2_loss_2: 5.8188e-04 - val_dense_2_loss_3: 2.7953e-07 - val_dense_2_loss_4: 8.0432e-05 - val_dense_2_loss_5: 2.4281e-04 - val_dense_2_loss_6: 6.1068e-07 - val_dense_2_loss_7: 1.1806e-04 - val_dense_2_loss_8: 1.0939e-04 - val_dense_2_acc_1: 1.0000 - val_dense_2_acc_2: 0.9999 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 1.0000 - val_dense_2_acc_5: 1.0000 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 1.0000 - val_dense_2_acc_8: 1.0000\n",
      "Epoch 46/1000\n",
      "1000/1000 [==============================] - 246s 246ms/step - loss: 0.0013 - dense_2_loss_1: 1.3605e-04 - dense_2_loss_2: 6.5218e-04 - dense_2_loss_3: 2.6534e-07 - dense_2_loss_4: 8.3012e-05 - dense_2_loss_5: 2.3734e-04 - dense_2_loss_6: 6.6295e-07 - dense_2_loss_7: 1.1860e-04 - dense_2_loss_8: 1.0863e-04 - dense_2_acc_1: 1.0000 - dense_2_acc_2: 0.9999 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - val_loss: 0.0013 - val_dense_2_loss_1: 1.1936e-04 - val_dense_2_loss_2: 6.5499e-04 - val_dense_2_loss_3: 2.5881e-07 - val_dense_2_loss_4: 8.5243e-05 - val_dense_2_loss_5: 2.3745e-04 - val_dense_2_loss_6: 6.6559e-07 - val_dense_2_loss_7: 1.1511e-04 - val_dense_2_loss_8: 1.0794e-04 - val_dense_2_acc_1: 1.0000 - val_dense_2_acc_2: 0.9998 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 1.0000 - val_dense_2_acc_5: 1.0000 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 1.0000 - val_dense_2_acc_8: 1.0000\n",
      "Epoch 47/1000\n",
      "1000/1000 [==============================] - 246s 246ms/step - loss: 0.0013 - dense_2_loss_1: 1.5368e-04 - dense_2_loss_2: 6.6256e-04 - dense_2_loss_3: 2.6652e-07 - dense_2_loss_4: 7.9661e-05 - dense_2_loss_5: 2.2911e-04 - dense_2_loss_6: 6.1489e-07 - dense_2_loss_7: 1.1476e-04 - dense_2_loss_8: 1.0461e-04 - dense_2_acc_1: 0.9999 - dense_2_acc_2: 0.9999 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - val_loss: 0.0014 - val_dense_2_loss_1: 1.4939e-04 - val_dense_2_loss_2: 6.9564e-04 - val_dense_2_loss_3: 2.6344e-07 - val_dense_2_loss_4: 8.3543e-05 - val_dense_2_loss_5: 2.2493e-04 - val_dense_2_loss_6: 7.2101e-07 - val_dense_2_loss_7: 1.1476e-04 - val_dense_2_loss_8: 1.0282e-04 - val_dense_2_acc_1: 0.9999 - val_dense_2_acc_2: 0.9998 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 1.0000 - val_dense_2_acc_5: 1.0000 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 1.0000 - val_dense_2_acc_8: 1.0000\n",
      "Epoch 48/1000\n",
      "1000/1000 [==============================] - 246s 246ms/step - loss: 0.0013 - dense_2_loss_1: 1.4163e-04 - dense_2_loss_2: 6.5847e-04 - dense_2_loss_3: 2.5726e-07 - dense_2_loss_4: 7.6975e-05 - dense_2_loss_5: 2.1830e-04 - dense_2_loss_6: 6.2900e-07 - dense_2_loss_7: 1.1253e-04 - dense_2_loss_8: 1.0224e-04 - dense_2_acc_1: 1.0000 - dense_2_acc_2: 0.9998 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - val_loss: 0.0011 - val_dense_2_loss_1: 7.0343e-05 - val_dense_2_loss_2: 5.2198e-04 - val_dense_2_loss_3: 2.4865e-07 - val_dense_2_loss_4: 7.8307e-05 - val_dense_2_loss_5: 2.0400e-04 - val_dense_2_loss_6: 8.6848e-07 - val_dense_2_loss_7: 1.0986e-04 - val_dense_2_loss_8: 9.9936e-05 - val_dense_2_acc_1: 1.0000 - val_dense_2_acc_2: 0.9999 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 1.0000 - val_dense_2_acc_5: 1.0000 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 1.0000 - val_dense_2_acc_8: 1.0000\n",
      "Epoch 49/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 245s 245ms/step - loss: 0.0013 - dense_2_loss_1: 1.5340e-04 - dense_2_loss_2: 6.8492e-04 - dense_2_loss_3: 2.5861e-07 - dense_2_loss_4: 7.5033e-05 - dense_2_loss_5: 2.1013e-04 - dense_2_loss_6: 6.1940e-07 - dense_2_loss_7: 1.0858e-04 - dense_2_loss_8: 1.0045e-04 - dense_2_acc_1: 0.9999 - dense_2_acc_2: 0.9998 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - val_loss: 0.0014 - val_dense_2_loss_1: 1.4814e-04 - val_dense_2_loss_2: 7.1452e-04 - val_dense_2_loss_3: 2.5350e-07 - val_dense_2_loss_4: 8.2569e-05 - val_dense_2_loss_5: 2.0853e-04 - val_dense_2_loss_6: 5.4994e-07 - val_dense_2_loss_7: 1.0670e-04 - val_dense_2_loss_8: 9.8614e-05 - val_dense_2_acc_1: 0.9999 - val_dense_2_acc_2: 0.9998 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 1.0000 - val_dense_2_acc_5: 1.0000 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 1.0000 - val_dense_2_acc_8: 1.0000\n",
      "Epoch 50/1000\n",
      "1000/1000 [==============================] - 245s 245ms/step - loss: 0.0012 - dense_2_loss_1: 1.2595e-04 - dense_2_loss_2: 5.9858e-04 - dense_2_loss_3: 2.5529e-07 - dense_2_loss_4: 7.2014e-05 - dense_2_loss_5: 2.0178e-04 - dense_2_loss_6: 5.5481e-07 - dense_2_loss_7: 1.0520e-04 - dense_2_loss_8: 9.8097e-05 - dense_2_acc_1: 1.0000 - dense_2_acc_2: 0.9999 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - val_loss: 0.0011 - val_dense_2_loss_1: 1.0412e-04 - val_dense_2_loss_2: 5.7351e-04 - val_dense_2_loss_3: 2.5921e-07 - val_dense_2_loss_4: 7.0360e-05 - val_dense_2_loss_5: 1.9510e-04 - val_dense_2_loss_6: 5.7624e-07 - val_dense_2_loss_7: 1.0235e-04 - val_dense_2_loss_8: 9.5187e-05 - val_dense_2_acc_1: 1.0000 - val_dense_2_acc_2: 0.9999 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 1.0000 - val_dense_2_acc_5: 1.0000 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 1.0000 - val_dense_2_acc_8: 1.0000\n",
      "Epoch 51/1000\n",
      "1000/1000 [==============================] - 246s 246ms/step - loss: 0.0013 - dense_2_loss_1: 1.5510e-04 - dense_2_loss_2: 6.6420e-04 - dense_2_loss_3: 2.5760e-07 - dense_2_loss_4: 6.9154e-05 - dense_2_loss_5: 1.9284e-04 - dense_2_loss_6: 5.6315e-07 - dense_2_loss_7: 1.0075e-04 - dense_2_loss_8: 9.4088e-05 - dense_2_acc_1: 0.9999 - dense_2_acc_2: 0.9998 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - val_loss: 0.0012 - val_dense_2_loss_1: 1.6332e-04 - val_dense_2_loss_2: 5.7086e-04 - val_dense_2_loss_3: 2.4790e-07 - val_dense_2_loss_4: 6.7798e-05 - val_dense_2_loss_5: 1.8593e-04 - val_dense_2_loss_6: 6.5687e-07 - val_dense_2_loss_7: 1.0051e-04 - val_dense_2_loss_8: 9.1880e-05 - val_dense_2_acc_1: 0.9999 - val_dense_2_acc_2: 0.9999 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 1.0000 - val_dense_2_acc_5: 1.0000 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 1.0000 - val_dense_2_acc_8: 1.0000\n",
      "Epoch 52/1000\n",
      "1000/1000 [==============================] - 245s 245ms/step - loss: 0.0012 - dense_2_loss_1: 1.4046e-04 - dense_2_loss_2: 5.9594e-04 - dense_2_loss_3: 2.4937e-07 - dense_2_loss_4: 6.6889e-05 - dense_2_loss_5: 1.8246e-04 - dense_2_loss_6: 5.7431e-07 - dense_2_loss_7: 9.5947e-05 - dense_2_loss_8: 9.1270e-05 - dense_2_acc_1: 1.0000 - dense_2_acc_2: 0.9999 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - val_loss: 0.0012 - val_dense_2_loss_1: 1.2934e-04 - val_dense_2_loss_2: 6.2542e-04 - val_dense_2_loss_3: 2.5077e-07 - val_dense_2_loss_4: 6.0609e-05 - val_dense_2_loss_5: 1.7847e-04 - val_dense_2_loss_6: 4.5961e-07 - val_dense_2_loss_7: 9.2375e-05 - val_dense_2_loss_8: 8.9644e-05 - val_dense_2_acc_1: 1.0000 - val_dense_2_acc_2: 0.9998 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 1.0000 - val_dense_2_acc_5: 1.0000 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 1.0000 - val_dense_2_acc_8: 1.0000\n",
      "Epoch 53/1000\n",
      "1000/1000 [==============================] - 245s 245ms/step - loss: 0.0011 - dense_2_loss_1: 1.4864e-04 - dense_2_loss_2: 5.5903e-04 - dense_2_loss_3: 2.4415e-07 - dense_2_loss_4: 6.2443e-05 - dense_2_loss_5: 1.7182e-04 - dense_2_loss_6: 5.2228e-07 - dense_2_loss_7: 9.1140e-05 - dense_2_loss_8: 8.6705e-05 - dense_2_acc_1: 0.9999 - dense_2_acc_2: 0.9999 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - val_loss: 0.0012 - val_dense_2_loss_1: 1.5387e-04 - val_dense_2_loss_2: 6.2369e-04 - val_dense_2_loss_3: 2.4232e-07 - val_dense_2_loss_4: 6.4058e-05 - val_dense_2_loss_5: 1.6997e-04 - val_dense_2_loss_6: 5.1495e-07 - val_dense_2_loss_7: 8.9680e-05 - val_dense_2_loss_8: 8.8319e-05 - val_dense_2_acc_1: 0.9999 - val_dense_2_acc_2: 0.9998 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 1.0000 - val_dense_2_acc_5: 1.0000 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 1.0000 - val_dense_2_acc_8: 1.0000\n",
      "Epoch 54/1000\n",
      "1000/1000 [==============================] - 245s 245ms/step - loss: 0.0011 - dense_2_loss_1: 1.4327e-04 - dense_2_loss_2: 5.6082e-04 - dense_2_loss_3: 2.3660e-07 - dense_2_loss_4: 5.8059e-05 - dense_2_loss_5: 1.6190e-04 - dense_2_loss_6: 5.3360e-07 - dense_2_loss_7: 8.5884e-05 - dense_2_loss_8: 8.2312e-05 - dense_2_acc_1: 0.9999 - dense_2_acc_2: 0.9999 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - val_loss: 9.3343e-04 - val_dense_2_loss_1: 8.4607e-05 - val_dense_2_loss_2: 4.7296e-04 - val_dense_2_loss_3: 2.2169e-07 - val_dense_2_loss_4: 5.8690e-05 - val_dense_2_loss_5: 1.5529e-04 - val_dense_2_loss_6: 4.2191e-07 - val_dense_2_loss_7: 8.2290e-05 - val_dense_2_loss_8: 7.8951e-05 - val_dense_2_acc_1: 1.0000 - val_dense_2_acc_2: 0.9999 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 1.0000 - val_dense_2_acc_5: 1.0000 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 1.0000 - val_dense_2_acc_8: 1.0000\n",
      "Epoch 55/1000\n",
      "1000/1000 [==============================] - 246s 246ms/step - loss: 0.0013 - dense_2_loss_1: 1.2628e-04 - dense_2_loss_2: 5.1949e-04 - dense_2_loss_3: 2.3472e-07 - dense_2_loss_4: 5.5571e-05 - dense_2_loss_5: 1.5740e-04 - dense_2_loss_6: 5.3009e-07 - dense_2_loss_7: 2.0282e-04 - dense_2_loss_8: 1.9331e-04 - dense_2_acc_1: 1.0000 - dense_2_acc_2: 0.9999 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - val_loss: 0.0012 - val_dense_2_loss_1: 1.3974e-04 - val_dense_2_loss_2: 6.5232e-04 - val_dense_2_loss_3: 2.0636e-07 - val_dense_2_loss_4: 5.7042e-05 - val_dense_2_loss_5: 1.6601e-04 - val_dense_2_loss_6: 4.2169e-07 - val_dense_2_loss_7: 1.0079e-04 - val_dense_2_loss_8: 1.0491e-04 - val_dense_2_acc_1: 1.0000 - val_dense_2_acc_2: 0.9998 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 1.0000 - val_dense_2_acc_5: 1.0000 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 1.0000 - val_dense_2_acc_8: 1.0000\n",
      "Epoch 56/1000\n",
      "1000/1000 [==============================] - 245s 245ms/step - loss: 0.0011 - dense_2_loss_1: 1.3966e-04 - dense_2_loss_2: 5.6981e-04 - dense_2_loss_3: 2.2368e-07 - dense_2_loss_4: 5.5239e-05 - dense_2_loss_5: 1.5411e-04 - dense_2_loss_6: 4.4938e-07 - dense_2_loss_7: 8.2055e-05 - dense_2_loss_8: 7.4782e-05 - dense_2_acc_1: 0.9999 - dense_2_acc_2: 0.9999 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - val_loss: 9.5040e-04 - val_dense_2_loss_1: 8.4823e-05 - val_dense_2_loss_2: 5.1070e-04 - val_dense_2_loss_3: 2.3380e-07 - val_dense_2_loss_4: 5.3235e-05 - val_dense_2_loss_5: 1.5412e-04 - val_dense_2_loss_6: 4.3366e-07 - val_dense_2_loss_7: 7.7313e-05 - val_dense_2_loss_8: 6.9538e-05 - val_dense_2_acc_1: 1.0000 - val_dense_2_acc_2: 0.9999 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 1.0000 - val_dense_2_acc_5: 1.0000 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 1.0000 - val_dense_2_acc_8: 1.0000\n",
      "Epoch 57/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 245s 245ms/step - loss: 0.0011 - dense_2_loss_1: 1.5849e-04 - dense_2_loss_2: 5.8636e-04 - dense_2_loss_3: 2.2275e-07 - dense_2_loss_4: 5.4060e-05 - dense_2_loss_5: 1.4868e-04 - dense_2_loss_6: 4.6645e-07 - dense_2_loss_7: 7.6099e-05 - dense_2_loss_8: 6.8733e-05 - dense_2_acc_1: 0.9999 - dense_2_acc_2: 0.9999 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - val_loss: 9.9344e-04 - val_dense_2_loss_1: 1.3859e-04 - val_dense_2_loss_2: 5.1453e-04 - val_dense_2_loss_3: 2.1772e-07 - val_dense_2_loss_4: 5.3200e-05 - val_dense_2_loss_5: 1.4271e-04 - val_dense_2_loss_6: 4.1483e-07 - val_dense_2_loss_7: 7.6132e-05 - val_dense_2_loss_8: 6.7642e-05 - val_dense_2_acc_1: 0.9999 - val_dense_2_acc_2: 0.9999 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 1.0000 - val_dense_2_acc_5: 1.0000 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 1.0000 - val_dense_2_acc_8: 1.0000\n",
      "Epoch 58/1000\n",
      "1000/1000 [==============================] - 246s 246ms/step - loss: 0.0010 - dense_2_loss_1: 1.3192e-04 - dense_2_loss_2: 5.4126e-04 - dense_2_loss_3: 2.2456e-07 - dense_2_loss_4: 5.3158e-05 - dense_2_loss_5: 1.4479e-04 - dense_2_loss_6: 4.8895e-07 - dense_2_loss_7: 7.3516e-05 - dense_2_loss_8: 6.7596e-05 - dense_2_acc_1: 0.9999 - dense_2_acc_2: 0.9999 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - val_loss: 9.1946e-04 - val_dense_2_loss_1: 9.0765e-05 - val_dense_2_loss_2: 4.9458e-04 - val_dense_2_loss_3: 2.1926e-07 - val_dense_2_loss_4: 5.1425e-05 - val_dense_2_loss_5: 1.4238e-04 - val_dense_2_loss_6: 5.4169e-07 - val_dense_2_loss_7: 7.2859e-05 - val_dense_2_loss_8: 6.6691e-05 - val_dense_2_acc_1: 1.0000 - val_dense_2_acc_2: 0.9999 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 1.0000 - val_dense_2_acc_5: 1.0000 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 1.0000 - val_dense_2_acc_8: 1.0000\n",
      "Epoch 59/1000\n",
      "1000/1000 [==============================] - 245s 245ms/step - loss: 9.6114e-04 - dense_2_loss_1: 1.3731e-04 - dense_2_loss_2: 4.9179e-04 - dense_2_loss_3: 2.1899e-07 - dense_2_loss_4: 5.1461e-05 - dense_2_loss_5: 1.3990e-04 - dense_2_loss_6: 4.9353e-07 - dense_2_loss_7: 7.3153e-05 - dense_2_loss_8: 6.6809e-05 - dense_2_acc_1: 0.9999 - dense_2_acc_2: 0.9999 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - val_loss: 0.0011 - val_dense_2_loss_1: 1.8874e-04 - val_dense_2_loss_2: 6.0979e-04 - val_dense_2_loss_3: 2.3207e-07 - val_dense_2_loss_4: 4.6477e-05 - val_dense_2_loss_5: 1.3657e-04 - val_dense_2_loss_6: 3.8433e-07 - val_dense_2_loss_7: 7.1784e-05 - val_dense_2_loss_8: 6.6114e-05 - val_dense_2_acc_1: 0.9999 - val_dense_2_acc_2: 0.9999 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 1.0000 - val_dense_2_acc_5: 1.0000 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 1.0000 - val_dense_2_acc_8: 1.0000\n",
      "Epoch 60/1000\n",
      "1000/1000 [==============================] - 245s 245ms/step - loss: 9.3840e-04 - dense_2_loss_1: 1.2120e-04 - dense_2_loss_2: 4.9152e-04 - dense_2_loss_3: 2.2044e-07 - dense_2_loss_4: 5.0672e-05 - dense_2_loss_5: 1.3730e-04 - dense_2_loss_6: 4.4301e-07 - dense_2_loss_7: 7.0506e-05 - dense_2_loss_8: 6.6550e-05 - dense_2_acc_1: 1.0000 - dense_2_acc_2: 0.9999 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - val_loss: 9.4829e-04 - val_dense_2_loss_1: 1.5708e-04 - val_dense_2_loss_2: 4.7052e-04 - val_dense_2_loss_3: 2.1504e-07 - val_dense_2_loss_4: 4.7249e-05 - val_dense_2_loss_5: 1.3359e-04 - val_dense_2_loss_6: 3.9140e-07 - val_dense_2_loss_7: 7.2824e-05 - val_dense_2_loss_8: 6.6416e-05 - val_dense_2_acc_1: 0.9999 - val_dense_2_acc_2: 0.9999 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 1.0000 - val_dense_2_acc_5: 1.0000 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 1.0000 - val_dense_2_acc_8: 1.0000\n",
      "Epoch 61/1000\n",
      "1000/1000 [==============================] - 246s 246ms/step - loss: 9.7234e-04 - dense_2_loss_1: 1.2736e-04 - dense_2_loss_2: 5.3027e-04 - dense_2_loss_3: 2.1748e-07 - dense_2_loss_4: 4.8823e-05 - dense_2_loss_5: 1.3085e-04 - dense_2_loss_6: 4.2812e-07 - dense_2_loss_7: 6.9153e-05 - dense_2_loss_8: 6.5243e-05 - dense_2_acc_1: 0.9999 - dense_2_acc_2: 0.9999 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - val_loss: 9.0242e-04 - val_dense_2_loss_1: 1.2883e-04 - val_dense_2_loss_2: 4.6481e-04 - val_dense_2_loss_3: 2.1764e-07 - val_dense_2_loss_4: 4.6312e-05 - val_dense_2_loss_5: 1.2630e-04 - val_dense_2_loss_6: 3.6394e-07 - val_dense_2_loss_7: 6.7672e-05 - val_dense_2_loss_8: 6.7903e-05 - val_dense_2_acc_1: 0.9999 - val_dense_2_acc_2: 0.9999 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 1.0000 - val_dense_2_acc_5: 1.0000 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 1.0000 - val_dense_2_acc_8: 1.0000\n",
      "Epoch 62/1000\n",
      "1000/1000 [==============================] - 245s 245ms/step - loss: 9.4858e-04 - dense_2_loss_1: 1.2688e-04 - dense_2_loss_2: 5.1556e-04 - dense_2_loss_3: 2.1744e-07 - dense_2_loss_4: 4.6639e-05 - dense_2_loss_5: 1.2580e-04 - dense_2_loss_6: 4.5862e-07 - dense_2_loss_7: 6.7549e-05 - dense_2_loss_8: 6.5477e-05 - dense_2_acc_1: 0.9999 - dense_2_acc_2: 0.9999 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - val_loss: 8.2326e-04 - val_dense_2_loss_1: 1.2536e-04 - val_dense_2_loss_2: 4.0425e-04 - val_dense_2_loss_3: 2.1005e-07 - val_dense_2_loss_4: 4.3963e-05 - val_dense_2_loss_5: 1.2097e-04 - val_dense_2_loss_6: 3.5437e-07 - val_dense_2_loss_7: 6.6124e-05 - val_dense_2_loss_8: 6.2027e-05 - val_dense_2_acc_1: 1.0000 - val_dense_2_acc_2: 0.9999 - val_dense_2_acc_3: 1.0000 - val_dense_2_acc_4: 1.0000 - val_dense_2_acc_5: 1.0000 - val_dense_2_acc_6: 1.0000 - val_dense_2_acc_7: 1.0000 - val_dense_2_acc_8: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6d79590eb8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='loss', min_delta=0, patience=2, verbose=0, mode='auto')\n",
    "data_maker = dataset_generator(Tx, Ty, input_vocab, output_vocab, n_s, batch_size=1000)\n",
    "validation_maker = dataset_generator(Tx, Ty, input_vocab, output_vocab, n_s, batch_size=1000)\n",
    "model.fit_generator(data_maker, validation_data=validation_maker, validation_steps=100, steps_per_epoch=1000, epochs=1000, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source: noon\n",
      "output: 02:00:00\n",
      "source: five seconds past noon\n",
      "output: 12:00:05\n",
      "source: four o'clock in the morning\n",
      "output: 04:00:00\n",
      "source: half past eleven o'clock in the morning\n",
      "output: 11:30:00\n",
      "source: twenty nine minutes and fifty nine seconds past noon\n",
      "output: 12:29:59\n",
      "source: twenty nine minutes and fifty nine seconds past eleven o'clock at night\n",
      "output: 23:29:59\n",
      "source: twenty eight minutes to midnight\n",
      "output: 23:32:00\n"
     ]
    }
   ],
   "source": [
    "EXAMPLES = [\n",
    "    'noon',\n",
    "    'five seconds past noon',\n",
    "    \"four o'clock in the morning\",\n",
    "    \"half past eleven o'clock in the morning\",\n",
    "    \"twenty nine minutes and fifty nine seconds past noon\",\n",
    "    \"twenty nine minutes and fifty nine seconds past eleven o'clock at night\",\n",
    "    \"twenty eight minutes to midnight\"\n",
    "]\n",
    "\n",
    "for example in EXAMPLES:\n",
    "    source = string_to_int(example, Tx, input_vocab)\n",
    "    source = np.array(list(map(lambda x: to_categorical(x, num_classes=len(input_vocab)), source)))\n",
    "\n",
    "    prediction = model.predict([np.expand_dims(source, axis=0), np.zeros((1,n_s)), np.zeros((1,n_s))])\n",
    "    prediction = np.argmax(prediction, axis = -1)\n",
    "    output = [output_vocab_inv[int(i)] for i in prediction]\n",
    "    \n",
    "    print(\"source:\", example)\n",
    "    print(\"output:\", ''.join(output))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving themodel.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/opyate/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py:2361: UserWarning: Layer lstm_1 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 's0:0' shape=(?, 128) dtype=float32>, <tf.Tensor 'c0:0' shape=(?, 128) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  str(node.arguments) + '. They will not be included '\n",
      "/home/opyate/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py:2361: UserWarning: Layer lstm_1 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1/TensorArrayReadV3:0' shape=(?, 128) dtype=float32>, <tf.Tensor 'lstm_1/while/Exit_3:0' shape=(?, 128) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  str(node.arguments) + '. They will not be included '\n",
      "/home/opyate/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py:2361: UserWarning: Layer lstm_1 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1_1/TensorArrayReadV3:0' shape=(?, 128) dtype=float32>, <tf.Tensor 'lstm_1_1/while/Exit_3:0' shape=(?, 128) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  str(node.arguments) + '. They will not be included '\n",
      "/home/opyate/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py:2361: UserWarning: Layer lstm_1 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1_2/TensorArrayReadV3:0' shape=(?, 128) dtype=float32>, <tf.Tensor 'lstm_1_2/while/Exit_3:0' shape=(?, 128) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  str(node.arguments) + '. They will not be included '\n",
      "/home/opyate/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py:2361: UserWarning: Layer lstm_1 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1_3/TensorArrayReadV3:0' shape=(?, 128) dtype=float32>, <tf.Tensor 'lstm_1_3/while/Exit_3:0' shape=(?, 128) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  str(node.arguments) + '. They will not be included '\n",
      "/home/opyate/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py:2361: UserWarning: Layer lstm_1 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1_4/TensorArrayReadV3:0' shape=(?, 128) dtype=float32>, <tf.Tensor 'lstm_1_4/while/Exit_3:0' shape=(?, 128) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  str(node.arguments) + '. They will not be included '\n",
      "/home/opyate/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py:2361: UserWarning: Layer lstm_1 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1_5/TensorArrayReadV3:0' shape=(?, 128) dtype=float32>, <tf.Tensor 'lstm_1_5/while/Exit_3:0' shape=(?, 128) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  str(node.arguments) + '. They will not be included '\n",
      "/home/opyate/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py:2361: UserWarning: Layer lstm_1 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1_6/TensorArrayReadV3:0' shape=(?, 128) dtype=float32>, <tf.Tensor 'lstm_1_6/while/Exit_3:0' shape=(?, 128) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  str(node.arguments) + '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving themodel-weights.h5\n"
     ]
    }
   ],
   "source": [
    "# happy?\n",
    "\n",
    "import os\n",
    "\n",
    "modelfile = \"themodel.h5\"\n",
    "if os.path.isfile(modelfile):\n",
    "    print('already exists', modelfile)\n",
    "else:\n",
    "    print('saving', modelfile)\n",
    "    model.save(modelfile)\n",
    "\n",
    "modelweightsfile = \"themodel-weights.h5\"\n",
    "if os.path.isfile(modelweightsfile):\n",
    "    print('already exists', modelweightsfile)\n",
    "else:\n",
    "    print('saving', modelweightsfile)\n",
    "    model.save_weights(modelweightsfile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "See `attention.ipynb` for the attention map."
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "nlp-sequence-models",
   "graded_item_id": "n16CQ",
   "launcher_item_id": "npjGi"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
